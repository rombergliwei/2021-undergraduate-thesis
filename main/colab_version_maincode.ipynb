{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import seed\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard\n",
    "from keras import backend as keras\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "seed(12345)\n",
    "print(np.__version__)\n",
    "\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir(\"/content/drive/Colab Notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "mat=io.loadmat('TestTest8.mat', squeeze_me=True)\n",
    "np.save('TestTest8.npy',mat)\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "matt=io.loadmat('TestTest9.mat', squeeze_me=True)\n",
    "np.save('TestTest9.npy',matt)\n",
    "\n",
    "b = np.zeros(shape=(2000,32,32))\n",
    "\n",
    "bb = np.zeros(shape=(2000,32,32,2))\n",
    "\n",
    "for i in range(0, 2000):\n",
    "    #print(i)\n",
    "    pp=mat['koo'][i]\n",
    "    b[i,:,:]=pp\n",
    "\n",
    "for i in range(0, 2000):\n",
    "    #print(i)\n",
    "    pp=matt['TestTest9'][i][0]\n",
    "    bb[i,:,:,0]=pp\n",
    "    pp=matt['TestTest9'][i][1]\n",
    "    bb[i,:,:,1]=pp\n",
    "\n",
    "dd = np.zeros(shape=(2000,64,64,2))\n",
    "\n",
    "import cv2\n",
    "for i in range(0, 2000):\n",
    "    #print(i)\n",
    "   dd[i,:,:,0] = cv2.resize(bb[i,:,:,0],(64,64))\n",
    "   dd[i,:,:,1] = cv2.resize(bb[i,:,:,1],(64,64))\n",
    "\n",
    "d = np.zeros(shape=(2000,64,64))\n",
    "\n",
    "import cv2\n",
    "for i in range(0, 2000):\n",
    "    #print(i)\n",
    "   d[i,:,:] = cv2.resize(b[i,:,:],(64,64))\n",
    "\n",
    "data = d\n",
    "label = dd\n",
    "\n",
    "j = 1793\n",
    "#plt.figure(figsize=(4,2),dpi=200)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.squeeze(data[j,:,:]),cmap=plt.cm.gray)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.squeeze(label[j,:,:,0]),interpolation=\"bilinear\",vmin=0.2,vmax=1.0,cmap=plt.cm.gray)\n",
    "#figname = './fig/data_' +str(j)+'.jpg'\n",
    "#plt.savefig(figname)\n",
    "\n",
    "def Z_ScoreNormalization(x):\n",
    "    for i in range(len(x)):\n",
    "        mu = np.average(x[i,:])\n",
    "        sigma = np.std(x[i,:])\n",
    "        x[i,:] = (x[i,:] - mu) / sigma;\n",
    "    return x;\n",
    "\n",
    "# normalize data\n",
    "data = Z_ScoreNormalization(data)\n",
    "data = np.reshape(data,(2000,64,64,1))\n",
    "label = np.reshape(label,(2000,64,64,2))\n",
    "# split the train_data and val_data\n",
    "train_data = data[0:1600]\n",
    "val_data = data[1600:2000]\n",
    "train_label = label[0:1600]\n",
    "val_label = label[1600:2000]\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(train_label.shape)\n",
    "print(val_label.shape)\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, MaxPooling2D, UpSampling2D, Dropout, Conv2D, Concatenate, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "# define conv_factory: batch normalization + ReLU + Conv2D + Dropout (optional)\n",
    "def conv_factory(x, concat_axis, nb_filter,\n",
    "                 dropout_rate=None, weight_decay=1E-4):\n",
    "    x = BatchNormalization(axis=concat_axis,\n",
    "                           gamma_regularizer=l2(weight_decay),\n",
    "                           beta_regularizer=l2(weight_decay))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(nb_filter, (5, 5), dilation_rate=(2, 2),\n",
    "               kernel_initializer=\"he_uniform\",\n",
    "               padding=\"same\",\n",
    "               kernel_regularizer=l2(weight_decay))(x)\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# define dense block\n",
    "def denseblock(x, concat_axis, nb_layers, growth_rate,\n",
    "               dropout_rate=None, weight_decay=1E-4):\n",
    "    list_feat = [x]\n",
    "    for i in range(nb_layers):\n",
    "        x = conv_factory(x, concat_axis, growth_rate,\n",
    "                         dropout_rate, weight_decay)\n",
    "        list_feat.append(x)\n",
    "        x = Concatenate(axis=concat_axis)(list_feat)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "# define model U-net modified with dense block\n",
    "def get_model_deep_speckle():\n",
    "    inputs = Input((64, 64, 1))\n",
    "    print(\"inputs shape:\", inputs.shape)\n",
    "\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    print(\"conv1 shape:\", conv1.shape)\n",
    "    db1 = denseblock(x=conv1, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db1 shape:\", db1.shape)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(db1)\n",
    "    print(\"pool1 shape:\", pool1.shape)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    print(\"conv2 shape:\", conv2.shape)\n",
    "    db2 = denseblock(x=conv2, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db2 shape:\", db2.shape)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(db2)\n",
    "    print(\"pool2 shape:\", pool2.shape)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    print(\"conv3 shape:\", conv3.shape)\n",
    "    db3 = denseblock(x=conv3, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db3 shape:\", db3.shape)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(db3)\n",
    "    print(\"pool3 shape:\", pool3.shape)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    print(\"conv4 shape:\", conv4.shape)\n",
    "    db4 = denseblock(x=conv4, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db4 shape:\", db4.shape)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(db4)\n",
    "    print(\"pool4 shape:\", pool4.shape)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    print(\"conv5 shape:\", conv5.shape)\n",
    "    db5 = denseblock(x=conv5, concat_axis=3, nb_layers=4, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db5 shape:\", db5.shape)\n",
    "    up5 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(db5))\n",
    "    print(\"up5 shape:\", up5.shape)\n",
    "    merge5 = Concatenate(axis=3)([db4, up5])\n",
    "    print(\"merge5 shape:\", merge5.shape)\n",
    "\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n",
    "    print(\"conv6 shape:\", conv6.shape)\n",
    "    db6 = denseblock(x=conv6, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db5 shape:\", db6.shape)\n",
    "    up6 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(db6))\n",
    "    print(\"up6 shape:\", up6.shape)\n",
    "    merge6 = Concatenate(axis=3)([db3, up6])\n",
    "    print(\"merge6 shape:\", merge6.shape)\n",
    "\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    print(\"conv7 shape:\", conv7.shape)\n",
    "    db7 = denseblock(x=conv7, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db7 shape:\", db7.shape)\n",
    "    up7 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(db7))\n",
    "    print(\"up7 shape:\", up7.shape)\n",
    "    merge7 = Concatenate(axis=3)([db2, up7])\n",
    "    print(\"merge7 shape:\", merge7.shape)\n",
    "\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    print(\"conv8 shape:\", conv8.shape)\n",
    "    db8 = denseblock(x=conv8, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db8 shape:\", db8.shape)\n",
    "    up8 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(db8))\n",
    "    print(\"up8 shape:\", up8.shape)\n",
    "    merge8 = Concatenate(axis=3)([db1, up8])\n",
    "    print(\"merge8 shape:\", merge8.shape)\n",
    "\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    print(\"conv9 shape:\", conv9.shape)\n",
    "    db9 = denseblock(x=conv9, concat_axis=3, nb_layers=3, growth_rate=16, dropout_rate=0.5)\n",
    "    print(\"db9 shape:\", db9.shape)\n",
    "    conv10 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(db9)\n",
    "    print(\"conv10 shape:\", conv10.shape)\n",
    "    conv11 = Conv2D(2, 1, activation='softmax')(conv10)\n",
    "    print(\"conv11 shape:\", conv11.shape)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv11)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_model_deep_speckle()\n",
    "\n",
    "#model = unet()\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "# checkpoint\n",
    "filepath=\"check1channel/fault.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy',verbose=1, save_best_only=True,save_weights_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "print(\"data prepared, ready to train!\")\n",
    "# Fit the model\n",
    "history = model.fit(train_data, train_label,\n",
    "#                     validation_split=0.2,\n",
    "                    validation_data=(val_data,val_label),\n",
    "                    epochs=10000,\n",
    "                    batch_size=20,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
